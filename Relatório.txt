Dia 1:
Statlog Dataset:

Acurácia da Decision Tree: 
- 69,11% para dataset pre-processado 
- 67.64% com dataset original.

obs: tamanho do conjunto de testes: 25%

A Feature "Age" teve P-value de 0.799, as demais obtiveram P-value inferior a 0.15 
de acordo com api statsmodels.formula do python.

Dia 2:

Na plataforma Gretl a feature "Age" obteve o P-value superior a 0.50 e o modelo com
a variável apresentou a métrica adjusted R-squared de 0.522155, ao retirar esta feature
o modelo apresentou a métrica adjusted R-squared de 0,523199, outras features obtiveram
o p-value acima de 0.05, porém ao retira-las percebe-se uma queda na métrica adjusted
R-squared, portanto vejo como válido mantê-las.

Acurácia da Decision Tree:
-69.11% para o dataset original sem a feature "Age"
-75% para o dataset pre-processado sem a feature "Age"

obs: tamanho do conjunto de testes: 25% da base de dados

Acurácia da Decision Tree:
-75.92% para o dataset pre-processado sem a feature "Age"
tamanho do conjunto de testes: 20%.

-85.18% para o dataset pre-processado sem a feature "Age"
tamanho do conjunto de testes: 10%

Cleveland Dataset:

No presente Dataset a feature idade apresenta o p-value de 0.193, outra diferença em 
relação ao Dataset de Statlog é que a feature "chol" possui o p-value de 0.543, o que o
torna passível de extração. 

Acurácia da Decision Tree:
-70.49% para o dataset original
-75.40% para o dataset pre-processado

Acurácia da Decision Tree:
-67.21% para o dataset original sem a feature "age"
-73.77% para o dataset pre-processado sem a feature "age" 

Statlog e Cleveland Datasets:

Acurácia da Decision Tree:
-99.25% usando o dataset pre-processado de cleveland para treino e de statlog para teste
-96.69% usando o dataset pre-processado de statlog para treino e de clevelando para teste

Dia 3:

Foi observado que a base de dados de cleveland estava pre-processada os valores que
na base de dados original estavam ausentes foram alterados para "-1". Visto isso
foi utilizado a biblioteca "Imputer" para cuidar dos dados ausentes, foi usado a
estratégia do mais frequente(Moda) para substituir os dados ausentes. Assim novos
testes foram realizados usando a base de dados original de cleveland. Os mesmos
resultados do dia anterior foram obtidos (99.25% de acurácia usando a base pre-processada).

Dia 4:

Observando que os testes anteriores no datasets separados "DT_cleveland_prediction.py" e 
"DT_statlog_prediction.py" foram feitos usando método hold-out para treino e predição
dos casos, estes novos testes foram feitos com o método 10-fold cross validation para análise
dos resultados usando a acurácia como métrica.

obs: as bases de dados usadas foram as completas com as 13 features aconselhadas pela
especificação das bases, os dados foram padronizados para ficarem na mesma escala e os
dados ausentes foram preenchidos com a moda no caso da base de dados de cleveland.

Resultados: 
	DT_cleveland_prediction.py: 75.49%
	DT_statlog_prediction.py: 72.59%

Dia 5:

Análises utilizando O Software Tableau 10.4 foram feitas na base de dados de cleveland.
Apenas uma parte da bateria de análises foram feitas, basicamente apenas para visualização
de variáveis categóricas e usando agrupamentos nas variáveis discretas. Em todos os casos
é usado a feature "Diagnostic" para visualização da quantidade de Pessoas com doença do
coração ou não.

Obs: A base de dados foi pre-processada, a variável dependente teve teve os valores
originais modificados, inicialmente eram [0-4] sendo que '0' representava chances menores
de 50% de o paciente possuir doença do coração e a partir de '1' as representava chances
maiores de 50%, aumentando a gravidade. O pre-processamento foi feito visando simplificar
o diagnóstico mudando os valores diferentes de '0' e '1' para '1', assim representando
apenas chances maiores de 50% de se ter doença do coração.

Para gerar novos gráficos foi considerado usar o p-value das features para mostrar de forma
visual o quanto elas afetam no diagnóstico.

Obs: O p-value foi encontrado usando o Mínimo Quadrados Ordinários (Ordinary Least Squares)
do software Gretl.

Features	 P-value      
Thal		 1,04e^-05    
Age		 0,8024
Sex		 0,0021   
CP		 0,0002   
Trestbps	 0,1160
Chol		 0,3322
Fbs		 0,2497
Restecg		 0,1216
Thalach		 0,0344
Exang		 0,0030
Oldpeak		 0,1026	      
Slope		 0,1399	      
CA		 2,18e^-07

R-quadrado ajustado: 0,505516

O Gráfico que apresenta a feature Ca por Thal mostra que com Thal tendo o valor "Normal"
e Ca sendo igual a '0', há 117 casos representando mais de 33% dos casos da base de dados
e desses, 103 apresentam chances menores de 50% de possuir doença do coração.
 
Para Thal tendo o valor "Fixed Defect", o número de total de
casos é 19, não apresentando nem 10% da base de dados e desses apenas 7 possuem o risco de
ter doença do coração menor do que 50%, ou seja diagnostic tendo o valor '0'. É visível
também a predominancia de pacientes com chances maiores de 50% de ter doença do coração no
caso de Thal ter o valor "Reversable Defect" o qual possui 117 casos sendo que desses apenas
28 casos apresentam chances menores de 50% de o paciente ter doença do coração.

O Gráfico da feature "Age" mostra que há sim um crescimento no número de doenças
de coração nos pacientes com idade maior ou igual a 56 anos, portanto a feature, apesar de
ter apresentado p-value de 0,8024 no teste OLS do Gretl, deve ser considerado para o diagnóstico
de doença do coração.

O gráfico da feature Chol mostra que os valores acima de 253 apresentam maior chance se ter
doença do coração, visto que a partir deste valor a quantidade de pacientes com chances maiores
de 50% de se ter doença do coração estão acima da media geral.

No gráfico da feature Fbs, ha 258 registros com o valor "False" e 55 com o valor "True", e a
o numero de pacientes com chances maiores de 50% de ter doença do coração está na media em 
ambos os casos, o que deixa uma dúvida quanto a necessidade desta feature.

No Gretl, ao retirar a Feature Fbs por causa dos resultados observados nos gráficos é visto
que o valor da métrica R-quadrado ajustado diminui para 0,5049 o que implica que o modelo teve
perda de desempenho, assim considera-se a inserção de Fbs no modelo novamente.

Usando agora a acurácia do modelo como métrica para validação foi descoberto que com todas as
features o modelo prevê com 74,78% enquanto sem a feature "Fbs" o modelo prevê com 75.43%,
o que novamente põe a necessidade desta feature em questão.
Obs: O teste foi feito no arquivo "DT_cleveland_prediction.py" com dados pre-processados, 
usando as bibliotecas LabelEncoder para codificação dos valores categoricos, Imputer para
inserção de valores ausentes, OneHotEncoder para transformar os valores categoricos codificados
pelo LabelEncoder em Dummy Variables e a StandardScale para padronização dos valores das variáveis
numéricas contínuas.

Variáveis que faltam análises:

Restecg		 
Thalach		 
Exang		 
Oldpeak		 	      
Slope		 	 
Sex		    
CP		  
Trestbps	

Dia 6:

Com os resultados do dia anterior foi considerado retirar a feature Fbs do script
"DT_cleveland_statlog.py" obtendo sem esta uma acurácia entre 99.62% e 100%, um resultado
nao muito diferente dos resultados com a feature Fbs, o que mostra que a presença desta
não resulta em perda ou ganho no modelo de Aprendizado de Máquina.

Foi criado um template em python para treinamento e predição dos modelos 
de Aprendizado de Máquina, template este que ja foi utilizado no "DT_cleveland_prediction.py",
o código em questão ficou mais limpo e legível, com necessidade de importar apenas a biblioteca
'templates.py' criada para auxiliar os códigos em python deste projeto.

Dia 7:

O Template criado no dia anterior ("templates.py") foi usado na atualização do script 
"DT_statlog_prediction.py", funcionou bem sem alterações.